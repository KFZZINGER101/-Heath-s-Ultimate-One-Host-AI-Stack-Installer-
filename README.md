
> **New in this build:** GUI toggle for **Advanced Diagnostics Logging** (optional). Basic logs stay simple; advanced logs add PID/Thread, CPU/RAM %, disk I/O samples, step timing, and exceptions. A **Personal README** is auto-generated on Desktop after install.

# ğŸ¤  Heathâ€™s Ultimate One-Host AI Stack Installer
**Repo:** [KFZZINGER101/Heath-s-Ultimate-One-Host-AI-Stack-Installer](https://github.com/KFZZINGER101/Heath-s-Ultimate-One-Host-AI-Stack-Installer.git)

ğŸ”¥ **The most powerful free offline + online uncensored AI stack of 2025**

A single PowerShell script that automatically installs, configures, and links together every major open-source AI tool â€” large-language models, image generation, interpreters, and developer utilities â€” into **one unified local hub** at  
ğŸ‘‰ **[http://localhost:3000](http://localhost:3000)**  

No API keys â€¢ No subscriptions â€¢ No censorship â€¢ 100 % transparent  


---

## ğŸ§­ What This Script Does
---

## ğŸªŸ GUI Edition (New for 2025)

**Heath's AI Installer GUI** adds a full Windows Forms interface with:
- Automatic admin elevation prompt (asks to relaunch as Administrator).
- Full Install vs Custom Install mode.
- Category checkboxes for Core Tools, AI Tools, Models, Enhancements, and ComfyUI Extras.
- Scrollable sub-options for individual AI components (Ollama, ComfyUI, A1111, Open WebUI).
- Progress bar and live status display.
- Saves custom selections to a JSON config for reuse in command-line installs.

**GUI Features:**
| Feature | Description |
|----------|--------------|
| ğŸ§© **Run Full Install** | Installs everything automatically without prompts. |
| âš™ï¸ **Run Custom Install** | Lets you pick individual components before continuing. |
| ğŸ§± **Admin Auto-Elevation** | Relaunches itself as Administrator if not already. |
| ğŸª„ **Progress Tracking** | Visual progress bar and real-time status labels. |
| ğŸ§¾ **Persistent Choices** | Stores custom install selections for next launch. |

---

## ğŸ§© Deep System Diagnostics

The installer performs **hardware benchmarking** before setup:

| Test | Description |
|------|--------------|
| ğŸ’¾ Disk I/O Test | Writes and reads 100 MB to measure disk speed (warns if <100MB/s). |
| ğŸŒ Network Test | Runs `speedtest-cli` to check internet download speed. |
| ğŸ§  RAM & Disk Space Check | Logs total memory and warns if <16GB RAM or <60GB free space. |
| ğŸ§® CPU Benchmark | Multi-threaded matrix math test using PyTorch. |
| ğŸ§© GPU Benchmark | Detects NVIDIA, AMD, or Intel GPUs and runs PyTorch GPU vs CPU comparison. |

The results determine which backend (CUDA / ROCm / Intel / CPU) gets installed automatically.

---

## ğŸ¨ Model Management (SDXL Integrity Check)

SDXL Base 1.0 is automatically downloaded, verified, and shared between ComfyUI and A1111.

**Integrity Check System:**
- Verifies SHA256 hash before and after download.
- Redownloads automatically if the file is incomplete or corrupted.
- Logs model status and links it to A1111â€™s model folder automatically.

---

## ğŸ§  Auto-Tuning & Launch Scripts

The installer creates optimized launchers for each tool:

| Tool | Auto-Tune Features |
|------|---------------------|
| ğŸ§  **A1111** | Creates `webui-user.bat` with flags based on VRAM (lowvram, medvram, or CUDA). |
| ğŸ§© **ComfyUI** | Creates `start_comfyui.bat` with tuned PyTorch memory allocation. |
| âš™ï¸ **Torch** | Installs the matching build (CUDA, ROCm, Intel, or CPU). |

---

## ğŸ§© ComfyUI Enhancements

Adds ready-to-use workflows and nodes:
- Downloads **SDXL_base_only.json** and **SDXL_advanced.json** automatically.
- Installs **ComfyUI-Custom-Scripts** repository if missing.
- Suggests workflow configuration in the log file.

---

## ğŸŒ Open WebUI (Main Hub)

The installer automatically:
- Starts Docker Desktop and waits until Docker is ready.
- Runs the **Open WebUI container** with GPU or CPU image automatically.
- Configures **auto-restart** (`--restart unless-stopped`).
- Writes **`config.json`** with connected tools (Ollama, ComfyUI, A1111).
- Detects local models and sets the best default automatically.
- Tunes performance mode (CPU / GPU).

---

## ğŸ” Autostart, Recovery & Task Scheduler

The installer creates:
- ğŸ–‡ï¸ Desktop shortcut â†’ **Start My AI.lnk**
- ğŸ” Restart script â†’ **Restart_AI_Services.bat**
- ğŸ§± Task Scheduler job â†’ **HeathAIStack** (runs on login)
- â™»ï¸ Retry system â†’ If Docker isnâ€™t ready, retries every 10 seconds up to 9 times.
- ğŸ§© Recovery policy â†’ Repeats startup every 5 minutes if a failure occurs.

---

## ğŸ§© Full Logging & Guides

Every step is written to:
- **AI_Installer_Log.txt** (on Desktop) â€” logs categories `[SYSTEM] [GPU] [MODEL] [AI] [AUTOSTART]` etc.
- Auto-opens in Notepad at the end with a Quick Start guide and ASCII map of your AI stack.

---

## ğŸ“Š Summary of All Added Features

âœ… GUI-based install with Full & Custom modes  
âœ… Auto-admin relaunch  
âœ… Hardware detection & benchmarking (RAM, disk, CPU, GPU, network)  
âœ… Disk I/O and Speedtest integration  
âœ… SHA256-verified SDXL download + A1111 mirror  
âœ… Torch auto-select for CUDA/ROCm/Intel/CPU  
âœ… VRAM-aware auto-tuning for A1111 & ComfyUI  
âœ… Docker recovery & restart policy  
âœ… Open WebUI auto-configuration  
âœ… Task Scheduler with 5-minute retry recovery  
âœ… ComfyUI presets and custom node installer  
âœ… Persistent logs and Quick Start guide launch  

---

 â€“ Step by Step
| Stage | Description |
|:--|:--|
| **1ï¸âƒ£ Logging System** | Creates `AI_Installer_Log.txt` on Desktop with timestamps and categories (`SYSTEM`, `INSTALL`, `GPU`, etc.). |
| **2ï¸âƒ£ Admin Check** | Ensures PowerShell is run as Administrator. |
| **3ï¸âƒ£ System Checks** | Detects RAM, free disk, and tests disk I/O speed. |
| **4ï¸âƒ£ Network Test** | Runs `speedtest-cli`; logs download speed. |
| **5ï¸âƒ£ Dependency Install** | Installs Git, Docker Desktop (WSL2), Python 3.12, Ollama, VC++ Runtime, VS Code via Winget. |
| **6ï¸âƒ£ VS Code Extensions** | Auto-installs AI and dev extensions. |
| **7ï¸âƒ£ Clone Repos** | Downloads ComfyUI and Automatic1111 (A1111). |
| **8ï¸âƒ£ Python & Torch** | Creates venv and installs the right PyTorch build (CUDA / ROCm / Intel / CPU). |
| **9ï¸âƒ£ GPU Benchmark** | Detects GPU type + runs matrix tests vs CPU. |
| **ğŸ”Ÿ CPU Benchmark** | Runs multi-threaded torch matrix test. |
| **11ï¸âƒ£ Recommendations** | Summarises RAM/disk/network suggestions. |
| **12ï¸âƒ£ SDXL Model** | Downloads Stable Diffusion XL (~6 GB). |
| **13ï¸âƒ£ Model Linking** | Shares same checkpoint with A1111 & ComfyUI. |
| **14ï¸âƒ£ SD Auto-Tune** | Writes optimized launch flags based on VRAM. |
| **15ï¸âƒ£ A1111 Defaults** | Sets sampler = `DPM++ 2M Karras`, fixes configs. |
| **16ï¸âƒ£ ComfyUI Presets** | Adds example SDXL workflows + custom scripts. |
| **17ï¸âƒ£ Open WebUI Setup** | Starts Docker container for the main hub. |
| **18ï¸âƒ£ Restart Policy** | Sets `unless-stopped` for auto restart. |
| **19ï¸âƒ£ WebUI Config** | Links Ollama â†’ LLMs, ComfyUI â†’ Images, A1111 â†’ Alt UI, LangChain â†’ Tools. |
| **20ï¸âƒ£ Ollama Models** | Pulls Llama 3.1 8B, Mistral 7B, Phi-3 Medium, Code Llama 7B, Gemma 7B. |
| **21ï¸âƒ£ Autostart Scripts** | Creates desktop shortcut + `Restart_AI_Services.bat`. |
| **22ï¸âƒ£ Task Scheduler** | Runs stack on login. |
| **23ï¸âƒ£ Recovery** | Retries if Docker isnâ€™t ready. |
| **24ï¸âƒ£ Quick Guide** | Appends usage tips and opens Notepad. |
| **âœ… Finish** | When â€œInstaller finished!â€ appears, youâ€™re ready. |

---

## âš™ï¸ Core Installs
Git â€¢ Python 3.12 â€¢ VC++ Runtime â€¢ Docker Desktop (WSL2) â€¢ Visual Studio Code â€¢ Ollama  

---

## ğŸ¤– AI Stack Included
### ğŸ§© Open WebUI (Main Hub)
Web interface for chat, agents & tools â†’ [http://localhost:3000](http://localhost:3000)  
*(by Open WebUI Team â€” BSD-3 license)*  

### ğŸ§  Language Models (Ollama)
Pre-pulled: `llama3.1:8b`, `mistral:7b`, `phi3:medium`, `codellama:7b`, `gemma:7b`

### ğŸ¨ Image Generation
| Tool | Credits | License |
|:--|:--|:--|
| ComfyUI | Comfyanonymous | GPL-3.0 |
| Automatic1111 | AUTOMATIC1111 Team | AGPL-3.0 |
| Stable Diffusion XL Base 1.0 | Stability AI | CreativeML OpenRAIL-M |

Shared checkpoint â†’ no duplicate downloads.  

### ğŸ§© Agents & Tools
LangChain â€¢ Open-Interpreter â€¢ Continue.dev  

---

## âš¡ Adaptive Hardware Handling
Detects GPU type, installs matching Torch build, benchmarks CPU vs GPU, logs RAM/Disk/Network results, auto-selects best backend.  

---

## ğŸ§  Developer Environment
Installs VS Code + extensions like Continue.dev, GitLens, Prettier, Python, PowerShell, YAML, etc.  
Enables AI pair programming and smooth coding experience.  

---

## ğŸª„ Auto-Start & Recovery
- Desktop shortcut â†’ **Start My AI.lnk**  
- Restart script â†’ **Restart_AI_Services.bat**  
- Scheduled Task runs stack on login  
- Retries Docker until ready  
- Container auto-restarts on failure  

---

## ğŸ§° Folder Layout
```
C:\Users\<You>\
 â”œâ”€ ComfyUI\
 â”œâ”€ stable-diffusion-webui\
 â”œâ”€ .ollama\
 â”œâ”€ .open-webui\
 â””â”€ Desktop\
      â”œâ”€ AI_Installer_Log.txt
      â”œâ”€ Start My AI.lnk
      â””â”€ Restart_AI_Services.bat
```

---

## ğŸ§¾ Quick Install â€” Heath's Ultimate One-Host AI Stack
```powershell
cd "$env:USERPROFILE\Desktop"
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass -Force

# Force UTF-8 clean download from GitHub
$installerUrl = "https://raw.githubusercontent.com/KFZZINGER101/-Heath-s-Ultimate-One-Host-AI-Stack-Installer-/main/Heath_AI_Installer_GUI.ps1"
$installerFile = "Heath_AI_Installer_GUI.ps1"
Invoke-WebRequest -Uri $installerUrl -OutFile $installerFile -UseBasicParsing
(Get-Content $installerFile -Raw -Encoding UTF8) | Set-Content $installerFile -Encoding UTF8

# Run the installer
powershell.exe -ExecutionPolicy Bypass -File ".\Heath_AI_Installer_GUI.ps1"

# Download and open the README on Desktop
$readmeUrl = "https://raw.githubusercontent.com/KFZZINGER101/-Heath-s-Ultimate-One-Host-AI-Stack-Installer-/main/README.md"
$readmePath = "$env:USERPROFILE\Desktop\Heath_AI_Installer_README.md"
Invoke-WebRequest -Uri $readmeUrl -OutFile $readmePath -UseBasicParsing
Start-Process $readmePath

```

Then sit back and relax â€” the script does everything.  

After reboot, open your browser to ğŸ‘‰ **http://localhost:3000**

---

## ğŸ§¾ Quick-Start Cheat Sheet
| Feature | How to Use |
|:--|:--|
| ğŸ’¬ Chat | Talk with Ollama models (Llama 3, Mistral, Phi-3 â€¦) |
| ğŸ¨ Images | Use ComfyUI or A1111 inside the hub |
| ğŸ§  Agents | Enable LangChain & Interpreter in WebUI |
| ğŸ’» Coding | Open VS Code â†’ Continue.dev tab |
| ğŸ” Restart Stack | Run `Restart_AI_Services.bat` |
| ğŸ§° Logs | Check `AI_Installer_Log.txt` on Desktop |

---

## âš ï¸ Safety & Transparency
âœ… Uses only official sources (Winget + GitHub repos).  
ğŸ” Every action is logged in `AI_Installer_Log.txt`.  
ğŸ§± No external servers, spyware, or telemetry added.  
ğŸ§‘â€ğŸ’» Anyone can read the PowerShell script to verify.  

---

## ğŸ“œ Licensing
**Installer Script:** BSD 3-Clause License Â© 2025 KFZZINGER101 (Heath Duke)  

You may freely use, modify, and redistribute with credit.  
Do *not* use my name or branding to advertise forks.  

### Third-Party Licenses Summary
| Software | License |
|:--|:--|
| Open WebUI | BSD-3 |
| ComfyUI | GPL-3.0 |
| Automatic1111 | AGPL-3.0 |
| Stable Diffusion XL | CreativeML OpenRAIL-M |
| Ollama | Source-available |
| LangChain / Open-Interpreter / Continue.dev | MIT / Apache |
| Docker Desktop | Apache 2.0 |
| VS Code | MIT |
| Git | GPL-2.0 |
| Python | PSF License |

---

## ğŸ™Œ Credits & Acknowledgements
| Category | Contributors |
|:--|:--|
| **Author / Integrator** | **KFZZINGER101 (Heath Duke)** â€“ Creator of the PowerShell installer, auto-tuning system, benchmarking, logging & docs. |
| **AI Hub** | Open WebUI Team |
| **Model Runtime** | Ollama Developers |
| **Image Tools** | Comfyanonymous (ComfyUI) â€¢ AUTOMATIC1111 Team |
| **AI Models** | Stability AI â€¢ Meta AI â€¢ Mistral AI â€¢ Microsoft Research â€¢ Google DeepMind |
| **Agent Frameworks** | LangChain â€¢ Open-Interpreter |
| **Developer Integration** | Continue.dev Team â€¢ Microsoft VS Code |
| **Community** | Open-source contributors (2024â€“2025) who tested and improved the stack |

---

## ğŸ§© Folder & Service Summary Diagram
```
[ Windows PC ]
      â”‚
      â”œâ”€â”€ Docker Desktop â†’ Open WebUI (http://localhost:3000)
      â”‚       â”‚
      â”‚       â”œâ”€â”€ Ollama â†’ Local LLMs (Llama3 / Mistral / Phi3)
      â”‚       â”œâ”€â”€ ComfyUI â†’ Image Generation (SDXL)
      â”‚       â””â”€â”€ A1111 â†’ Alternate Image UI
      â”‚
      â”œâ”€â”€ VS Code â†’ Continue.dev AI coding
      â”œâ”€â”€ LangChain / Interpreter â†’ Local agents & tools
      â””â”€â”€ Logs + Shortcuts â†’ Desktop (for monitoring)
```

---

## ğŸ‰ Bottom Line
ğŸ’¥ One command installs a complete private AI workstation â€” ChatGPT-style chat â€¢ Stable Diffusion XL â€¢ Coding agents â€¢ Offline LLMs.  
Runs entirely on your computer, free and uncensored.  

```
ğŸ¤–ğŸ’¬ğŸ¨ğŸ› ï¸  All-in-One.  All Yours.
```

---

## ğŸ“‚ Repository Extras
### LICENSE (BSD 3-Clause)
```
BSD 3-Clause License
Â© 2025 KFZZINGER101 (Heath Duke)

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:
1. Redistributions must retain this notice and disclaimer.
2. The name KFZZINGER101 or Heath Duke may not be used to endorse derived products without permission.
3. This software is provided â€œas isâ€ without warranty of any kind.
```

### .gitignore
```
*.log
*.tmp
__pycache__/
venv/
.env
.cache/
.DS_Store
.ollama/
.open-webui/
ComfyUI/models/
stable-diffusion-webui/models/
```

### .gitattributes
```
* text=auto
*.ps1 text eol=crlf
*.md text eol=lf
```



---

## ğŸ§ª Advanced Technical Reference (Logging)

**Files**
- `AI_Installer_Log.txt` (human-readable)
- `AI_Installer_Log_Advanced.txt` (forensic-level; optional via GUI)
- Archive: `Desktop/AI_Installer_Logs_Archive/` (auto-zips when log > 20 MB)

**Advanced line format**
```
[YYYY-MM-DD HH:MM:SS.mmm Â±TZ] PID=12345 TID=7 CPU=17.3% MEM=42.1% DISKFREE=355.8GB :: [INSTALL] âœ… VS Code installed
    DETAIL: winget output / stderr trimmed
```

**What is captured**
- Timestamp with milliseconds, local timezone
- PowerShell PID + ThreadId
- CPU % (total), Memory % used, Disk C: free (GB)
- Category + Emoji status + message
- Optional details: step output, exception text, durations

**When it writes**
- On every `Log()` call across the installer
- Plus step-timers for key phases (dependency install, GPU/CPU tests, model downloads, Docker bring-up)

**Personal README**
- `Desktop/Personal_README.md` auto-generated on finish
- Summarizes system specs, selected options, models and services, log mode, and quick links

*This README was auto-merged on 2025-10-05 09:33:13Z.*
